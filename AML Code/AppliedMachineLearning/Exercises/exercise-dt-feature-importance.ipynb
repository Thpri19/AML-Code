{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "\n",
    "1. Use the **load_wine** data (remember to split your data into a train and test data). Go through the steps in the previous slides to find the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use the `load_wine` function to construct your dataset\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = \n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DT\n",
    "dt = \n",
    "\n",
    "# Fit your DT\n",
    "dt.\n",
    "\n",
    "# Predict on your test data with your DT\n",
    "y_test_hat = dt.\n",
    "\n",
    "# Obtain accuracy by using the `accuracy_score` function\n",
    "accuracy = \n",
    "\n",
    "# Print results\n",
    "print(f'DT with default settings achieved {round(accuracy * 100, 1)}% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 featuers. No need to change the code, but you can change the 10 to show fewer (or more) featuees\n",
    "import pandas as pd\n",
    "\n",
    "importances = dt.feature_importances_\n",
    "names = load_wine()['feature_names']\n",
    "\n",
    "feature_importance = pd.DataFrame(zip(names, importances), columns=['Feature', 'Importance'])\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False).reset_index()\n",
    "feature_importance[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it - no need to change anything, but you can change the 3 to another number if you want to show more features.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(feature_importance['Feature'][:3], feature_importance['Importance'][:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree based on most important features only\n",
    "top_features = (-importances).argsort()[:5]\n",
    "print(top_features)\n",
    "\n",
    "Z_train = X_train[:, ??]\n",
    "Z_test = X_test[:, ??]\n",
    "\n",
    "# Initialize a DT\n",
    "dt = \n",
    "\n",
    "# Fit your DT (on the Zs, i.e. the top featueres)\n",
    "dt.\n",
    "\n",
    "# Predict on your test data with your DT\n",
    "y_test_hat = \n",
    "\n",
    "# Obtain accuracy by using the `accuracy_score` function\n",
    "accuracy = \n",
    "\n",
    "# Print results\n",
    "print(f'DT with only top features achieved {round(accuracy * 100, 1)}% accuracy.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('amlfall22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3cedec8935a2c28d6fd602c3007747750e2af1c4c937c29fac0d323bf1b544b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
